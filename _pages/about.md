---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

<!-- 2020å¹´åœ¨<a href="http://www.ues.pku.edu.cn/old/szdw/qbjs/w/311950.htm" target="_blank">`ç‹ä»°éºŸæ•™æˆ`</a>ä¸<a href="http://www.ues.pku.edu.cn/jszy/pj/pjgrjl/47d5081a72b1402693d0ef0eac835be3.htm" target="_blank">`å½­å»ºæ•™æˆ`</a>æŒ‡å¯¼ä¸‹äºåŒ—äº¬å¤§å­¦è·å¾—åšå£«å­¦ä½ï¼ŒæœŸé—´æ›¾å‰å¾€ç¾å›½ä¸¤é™¢é™¢å£«<a href="https://search.asu.edu/profile/1227885" target="_blank">`Billie Turneræ•™æˆ`</a>è¯¾é¢˜ç»„è¿›è¡Œè”åˆåŸ¹å…»ã€‚ç°ä¸»è¦ä»äº‹æ™¯è§‚æ ¼å±€ä¸ç¤¾ä¼š-ç”Ÿæ€è¿‡ç¨‹é¢†åŸŸçš„ç ”ç©¶ï¼Œå‘è¡¨å›½å†…å¤–>æœŸåˆŠè®ºæ–‡50ä½™ç¯‡ï¼Œå«1ç¯‡Natureæ——ä¸‹æœŸåˆŠè®ºæ–‡ã€‚ -->


I am an assistant professor at <a href="https://www.cs.sjtu.edu.cn/" target="_blank">Computer Science and Engineering Department</a> in <a href="https://www.sjtu.edu.cn/" target="_blank">Shanghai Jiao Tong University (SJTU)</a>. I received the Master and Ph.D. degrees from Shanghai Jiao Tong University under the supervision of <a href="https://www.cs.sjtu.edu.cn/~chen-quan/index_EN.html" target="_blank">`Prof. Quan Chen`</a> and <a href="https://cs.sjtu.edu.cn/~guo-my/" target="_blank">`Prof. Minyi Guo`</a>. For now, I still work closely with <a href="https://www.cs.sjtu.edu.cn/~chen-quan/index_EN.html" target="_blank">`Prof. Quan Chen`</a> and <a href="https://raphael-hao.top/" target="_blank">`Assist Prof. Weihao Cui`</a>.

My previous research focused on:
- Task scheduling across various architectures
- Resource management in datacenters
- DNN inference system design

Currently, my research focus on: 
- Cloud computing and deep learning systems
- LLM inference and training systems
- Serverless architectures for diverse applications
- Advanced resource management in datacenters

**I am now looking for perspective Undergraduate Students and Master Students (Enrollment Date: 2026.09). If you are interested in above areas, we should talk.**

<span class='anchor' id='-xl'></span>

# ğŸ“ Education
- *2019.09 â€“ 2022.06*, Shanghai Jiao Tong University        `Doctor`
- *2016.09 â€“ 2019.03*, Shanghai Jiao Tong University        `Master`
- *2012.09 â€“ 2016.06*, Huazhong University of Science and Technology         `Bachelor`

<!-- <span class='anchor' id='-xsjz'></span>

# ğŸ’» å­¦æœ¯å…¼èŒ

- 2025-è‡³ä»Šï¼Œã€Šç”Ÿæ€å­¦æŠ¥ã€‹ `é’å¹´ç¼–å§”`
- 2024-è‡³ä»Šï¼Œã€ŠHuman and Ecological Risk Assessmentã€‹ `å‰¯ä¸»ç¼–`
- 2024-è‡³ä»Šï¼Œä¸­å›½ç”Ÿæ€å­¦ä¼šé’å¹´å·¥ä½œå§”å‘˜ä¼š `å‰¯ç§˜ä¹¦é•¿` -->

<span class='anchor' id='-fblw'></span>

# ğŸ“ Publications

### Preprint

- \* Denotes the `Corresponding author.`
- ^ Denotes the `Equal contribution.`
<!-- - Shulai Zhang, Ao Xu, Quan Chen, `Han Zhao`, Weihao Cui, Ningxin Zheng, Minyi Guo. Boosting Embodied AI Agents through Perception-Generation Disaggregation and Asynchronous Pipeline Execution. **(On Arxiv)**  -->
- Chuhao Xu, Zijun Li, Quan Chen, `Han Zhao`, Minyi Guo. LLM-Mesh: Enabling Elastic Sharing for Serverless LLM Inference. **(On Arxiv)** 
- Weihao Cui, Ji Zhang, `Han Zhao*`, Chao Liu, Wenhao Zhang, Jian Sha, Quan Chen, Bingsheng He, Minyi Guo. Xputimer: Anomaly diagnostics for divergent llm training in gpu clusters of thousand-plus scale. **(On Arxiv)** 
- Weihao Cui, Ziyi Xu, `Han Zhao`, Quan Chen, Zijun Li, Bingsheng He, Minyi Guo. Efficient Function-as-a-Service for Large Language Models with TIDAL. **(On Arxiv)** 
- Weihao Cui^, Yukang Chen^, `Han Zhao^`, Ziyi Xu, Quan Chen, Xusheng Chen, Yangjie Zhou, Shixuan Sun, Minyi Guo, M. Optimizing SLO-oriented LLM Serving with PD-Multiplexing. **(On Arxiv)**
- Chunyu Xue, Weihao Cui, `Han Zhao`, Quan Chen, Shulai Zhang, Pengyu Yang, Jing Yang, Shaobo Li, Minyi Guo. A codesign of scheduling and parallelization for large model training in heterogeneous clusters. **(On Arxiv)**

### Published

- Shulai Zhang, Ao Xu, Quan Chen, `Han Zhao`, Weihao Cui, Zhen Wang, Yan Li, Limin Xiao, Minyi Guo. Efficient Performance-Aware GPU Sharing with Compatibility and Isolation through Kernel Space Interception . **ATC2025 (CCF-A)** 
- `Han Zhao`, Weihao Cui, Quan Chen, Zijun Li, Zhenhua Han, Nan Wang, Yu Feng, Jieru Zhao, Chen Chen, Jingwen Leng, Minyi Guo. EDAS: Enabling Fast Data Loading for GPU Serverless Computing. **TACO2025 (CCF-A)** 
- Pengyu Yang, Weihao Cui, Chunyu Xue, `Han Zhao`, Chen Chen, Quan Chen, Jing Yang, Minyi Guo. Taming Flexible Job Packing in Deep Learning Training Clusters. **TACO2025 (CCF-A)** 
- Yifu He, `Han Zhao`, Quan Chen, Weihao Cui, Minyi Guo. ARACHNE: Optimizing distributed parallel applications with reduced inter-process communication. **TACO2025 (CCF-A)** 
- Shulai Zhang, Quan Chen, Weihao Cui, `Han Zhao`, Chunyu Xue, Zhen Zheng, Wei Lin, Minyi Guo. Improving GPU Sharing Performance through Adaptive Bubbleless Spatial-Temporal Sharing. **Eurosys2025 (CCF-A)** 
- Yu Feng, Weikai Lin, Zihan Liu, Jingwen Leng, Minyi Guo, `Han Zhao`, Xiaofeng Hou, Jieru Zhao, Yuhao Zhu. Potamoi: Accelerating neural rendering via a unified streaming architecture. **TACO2024 (CCF-A)**
- `Han Zhao^`, Junxiao Deng^, Weihao Cui, Quan Chen, Youtao Zhang, Deze Zeng, Minyi Guo. Adaptive Kernel Fusion for Improving the GPU Utilization while Ensuring QoS. **TC2024 (CCF-A)**
- `Han Zhao`, Junxiao Deng, Weihao Cui, Deze Zeng, Jing Yang, Minyi Guo. Exploiting all intra-SM parallelism to maximize the throughput while ensuring QoS. **Chinese Science Information Science 2024 (CCF-A)**
- Chuhao Xu, Yiyu Liu, Zijun Li, Quan Chen, `Han Zhao`, Deze Zeng, Qian Peng, Xueqi Wu, Haifeng Zhao, Senbo Fu, Minyi Guo. FaaSMem: Improving Memory Efficiency of Serverless Computing with Memory Pool Architecture. **In ASPLOS2024 (CCF-A)**
- Binghao Chen, `Han Zhao*`, Weihao Cui, Yifu He, Shulai Zhang, Quan Chen, Zijun Li, Minyi Guo. Maximizing the Utilization of GPUs Used by Cloud Gaming through Adaptive Co-location with Combo. **SoCC2023 (CCF-B)**
- `Han Zhao`, Weihao Cui, Quan Chen, Jingwen Leng, Deze Zeng, Minyi Guo. Improving Cluster Utilization Through Adaptive Resource Management for Deep Neural Network and CPU Jobs Colocation. **TC2023 (CCF-A)**
- `Han Zhao`, Weihao Cui, Quan Chen, Minyi Guo. ISPA: Exploiting Intra-SM Parallelism in GPUs via Fine-grained Resource Management. **TC2022 (CCF-A)**
- Weihao Cui, `Han Zhao`, Quan Chen, Hao Wei, Zirui Li, Deze Zeng, Chao Li, Minyi Guo. DVABatch: Diversity-aware Multi-Entry Multi-Exit Batching for Efficient Processing of DNN Services on GPUs. **ATC2022 (CCF-A)**
- `Han Zhao`, Weihao Cui, Quan Chen, Youtao Zhang, Yanchao Lu, Chao Li, Jingwen Leng, Minyi Guo. Tacker:Tensor-CUDA Core Kernel Fusion for Improving the GPU Utilization while Ensuring QoS. **HPCA2022 (CCF-A)**
- Weihao Cui, `Han Zhao`, Quan Chen, Ningxin Zheng, Jingwen Leng, Jieru Zhao, Zhuo Song, Tao Ma, Yong Yang, Chao Li, Minyi Guo. Enable Simultaneous DNN Services Based on Deterministic Operator Overlap and Precise Latency Prediction. **SC2021 (CCF-A)**
- `Han Zhao`, Weihao Cui, Quan Chen, Jieru Zhao, Jingwen Leng, Minyi Guo. Exploiting Intra-SM Parallelism in GPUs via Persistent and Elastic Blocks. **ICCD2021 (CCF-B)**
- Weihao Cui, Quan Chen, `Han Zhao`, Mengze Wei, Xiaoxin Tang, Minyi Guo. E2bird: Enhanced Elastic Batch for Improving Responsiveness and Throughput of Deep Learning Services. **TPDS2020 (CCF-A)**
- `Han Zhao`, Weihao Cui, Quan Chen, Jingwen Leng, Kai Yu, Deze Zeng, Chao Li, Minyi Guo. CODA: Improving Resource Utilization by Slimming and Co-locating DNN and CPU Jobs. **ICDCS2020 (CCF-B)**
- `Han Zhao`, Quan Chen, Yuxian Qiu, Ming Wu, Yao Shen, Jingwen Leng, Chao Li, Minyi Guo. Bandwidth and Locality Aware Task-stealing for Manycore Architectures with Bandwidth-Asymmetric Memory. **TACO2019 (CCF-A)**

<span class='anchor' id='-ryjx'></span>

# ğŸ… Awards
- 2025 **CCF Distinguished Paper** `CCFæ°å‡ºè®ºæ–‡å¥–`
- 2025 **MSRA StarTrack Scholar** `å¾®è½¯é“¸æ˜Ÿå­¦è€…`
- 2023 **CCF Outstanding Doctoral Dissertation Award in Computer Architecture** `CCFä½“ç³»ç»“æ„ä¼˜åš`
- 2021 **SC2021 Best Reproducibility Advancement** `SC2021æœ€ä½³å®ç°æåå¥–`

<span class='anchor' id='-kyxm'></span>

# ğŸ›ï¸ Projects

### National Project

- 2024-2026, **å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘é’å¹´é¡¹ç›®**ï¼ŒæœåŠ¡å™¨æ— æ„ŸçŸ¥è®¡ç®—çš„åŠ é€Ÿå™¨é«˜æ•ˆå…±äº«ç ”ç©¶ï¼ˆ`é¡¹ç›®è´Ÿè´£äºº`ï¼‰
- 2025-2027, **å›½å®¶é‡ç‚¹ç ”å‘è®¡åˆ’**, é’ˆå¯¹å¼‚æ„è®¡ç®—å¹³å°çš„èµ„æºå®æ—¶éš”ç¦»ä¸é«˜æ•ˆè°ƒåº¦ç³»ç»Ÿï¼ˆ`å®é™…é¡¹ç›®å®æ–½`ï¼‰
- 2024-2026, **å›½å®¶é‡ç‚¹ç ”å‘è®¡åˆ’**, é¢å‘æ–°ä¸€ä»£å›½äº§è¶…ç®—ç³»ç»Ÿçš„ç»Ÿä¸€å¹¶è¡Œç¼–ç¨‹æ¨¡å‹ä¸å¹¶è¡Œç¼–è¯‘ï¼ˆ`å­è¯¾é¢˜è´Ÿè´£äºº`ï¼‰
- 2023-2026, **å›½å®¶é‡ç‚¹ç ”å‘è®¡åˆ’**, æ–°å‹æ•°æ®æµå¼‚æ„å¤„ç†å™¨æ¶æ„åŠè®¡ç®—ç³»ç»Ÿï¼ˆ`å­è¯¾é¢˜è´Ÿè´£äºº`ï¼‰

### Industrial Project

- 2025-2026, **CCF-èš‚èšç»¿è‰²åŸºé‡‘**, æœ€å°åŒ–å¤§æ¨¡å‹æ¨ç†æˆæœ¬ï¼šåŒæ„åŠå¼‚æ„æ¨¡å‹æè‡´åˆå¹¶éƒ¨ç½²é™æœ¬ç ”ç©¶ï¼ˆ`é¡¹ç›®è´Ÿè´£äºº`ï¼‰
- 2024-2025, **HWäº‘è”åˆå®éªŒå®¤**, å¤§æ¨¡å‹æ¨ç†æœåŠ¡ä¸å¾®è°ƒä»»åŠ¡çš„é«˜æ•ˆæ··éƒ¨å…³é”®æŠ€æœ¯ç ”ç©¶æŠ€æœ¯ï¼ˆ`é¡¹ç›®è´Ÿè´£äºº`ï¼‰
- 2023-2024, **HWå§”æ‰˜ç ”ç©¶é¡¹ç›®**, æºç å¹¶è¡ŒåŒ–æ£€æµ‹ä¸æç¤ºå·¥å…·é¡¹ç›®ï¼ˆ`è”åˆé¡¹ç›®è´Ÿè´£äºº`ï¼‰
- 2023-2024, **HWå§”æ‰˜ç ”ç©¶é¡¹ç›®**, å•èŠ‚ç‚¹åˆ°å¤šèŠ‚ç‚¹å¹¶è¡Œåº”ç”¨æºåˆ°æºç¿»è¯‘å·¥å…·é¡¹ç›®ï¼ˆ`è”åˆé¡¹ç›®è´Ÿè´£äºº`ï¼‰

<!-- - 2023-2025ï¼Œ**å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘é’å¹´é¡¹ç›®**ï¼Œç©ºé—´æµåŠ¨è§†è§’ä¸‹æ°´è´¨å‡€åŒ–æœåŠ¡æƒ ç›Šæµ‹åº¦åŠå…¶å¯¹æ™¯è§‚æ ¼å±€æ¼”å˜çš„å“åº”ï¼šä»¥å¤ªæ¹–æµåŸŸä¸ºä¾‹ï¼ˆ`ä¸»æŒ`ï¼‰
- 2023-2027ï¼Œ**ç§‘æŠ€éƒ¨é‡ç‚¹ç ”å‘è®¡åˆ’å­è¯¾é¢˜**ï¼ˆ2023YFF1304700ï¼‰ï¼Œå¹²æ—±åŒºåŸå¸‚åŠå…¶å‘¨è¾¹åŒºåŸŸç”Ÿæ€ç©ºé—´éœ€æ°´é‡ç²¾ç»†åŒ–ä¼°ç®—ï¼ˆ`ä¸»æŒ`ï¼‰
- 2022-2023ï¼Œ**æ•™è‚²éƒ¨åœ°è¡¨è¿‡ç¨‹ä¸èµ„æºç”Ÿæ€å›½å®¶é‡ç‚¹å®éªŒå®¤å¼€æ”¾è¯¾é¢˜**ï¼ˆ2022-KF-03ï¼‰ï¼Œå¤ªæ¹–æµåŸŸç”Ÿæ€ç³»ç»ŸæœåŠ¡æƒè¡¡åˆ†æåŠé©±åŠ¨è¯†åˆ«ï¼šåŸºäºç²®é£Ÿ-æ°´-ç”Ÿæ€å…³è”è§†è§’ï¼ˆ`ä¸»æŒ`ï¼‰
- 2022-2023ï¼Œ**ä¸Šæµ·å¸ˆèŒƒå¤§å­¦å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘åŸ¹è‚²è®¡åˆ’**ï¼ˆSK202219ï¼‰ï¼Œå¤ªæ¹–æµåŸŸæ™¯è§‚æ ¼å±€æ¼”å˜å¯¹æ°´è´¨å‡€åŒ–æœåŠ¡çš„å½±å“æœºåˆ¶ï¼šåŸºäºç©ºé—´æµåŠ¨è§†è§’ï¼ˆ`ä¸»æŒ`ï¼‰
- 2022-2023ï¼Œ**ä¸Šæµ·é«˜æ ¡é’å¹´æ•™å¸ˆåŸ¹å…»èµ„åŠ©è®¡åˆ’é¡¹ç›®**ï¼ˆZZ202207005ï¼‰ï¼Œè¯¾ç¨‹æ€æ”¿æ”¹é©è¦æ±‚ä¸‹ã€Šåœ°ç†ç§‘å­¦å¯¼è®ºã€‹è¯¾å ‚æ•™å­¦è®¾è®¡ï¼ˆ`ä¸»æŒ`ï¼‰
- 2023-2024ï¼Œ**ä¸Šæµ·é«˜æ ¡å¸‚çº§é‡ç‚¹è¯¾ç¨‹**ï¼Œåœ°ç†ç§‘å­¦å¯¼è®ºï¼ˆå‚ä¸ï¼‰
- 2019-2021ï¼Œ**å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘å›½é™…ï¼ˆåœ°åŒºï¼‰åˆä½œä¸äº¤æµé¡¹ç›®**ï¼ˆ41911530080ï¼‰ï¼Œé™†-æ²³äº¤ç•Œé¢ç¤¾ä¼š-ç»æµ-ç¯å¢ƒæƒè¡¡ç®¡ç†ï¼ˆå‚ä¸ï¼‰ -->

<span class='anchor' id='-cdkc'></span>

# ğŸ“š Courses

- 2023.1 - Now, **Intelligent Computing Systems** `ã€Šæ™ºèƒ½è®¡ç®—ç³»ç»Ÿã€‹`
- 2023.1 - Now, **Parallel Computing and Parallel Algorithms** `ã€Šå¹¶è¡Œè®¡ç®—ä¸å¹¶è¡Œç®—æ³•ã€‹`

<!-- - 2023.1-è‡³ä»Šï¼Œ**æ™¯è§‚ä¸åŒºåŸŸç”Ÿæ€å­¦**ï¼ˆ3å­¦åˆ†ï¼‰ï¼Œæœ¬ç§‘ç”Ÿè¯¾ç¨‹
- 2022.1-è‡³ä»Šï¼Œ**åœ°ç†ä¿¡æ¯ç³»ç»ŸåŸç†**ï¼ˆ3å­¦åˆ†ï¼‰ï¼Œæœ¬ç§‘ç”Ÿè¯¾ç¨‹
- 2021.9-è‡³ä»Šï¼Œ**åœ°ç†ç§‘å­¦å¯¼è®º**ï¼ˆ3å­¦åˆ†ï¼‰ï¼Œæœ¬ç§‘ç”Ÿè¯¾ç¨‹ -->

<span class='anchor' id='-xszd'></span>

# ğŸ§‘â€ğŸ“ Students

### Non-Graduated
- `I am so glad to work with these outstanding students.ğŸ’–ğŸ’–`
- 2024çº§åšå£« é‚“ä¿Šéª
- 2024çº§ç¡•å£« å¾å¥¥ï¼Œé™ˆç…œåº·
- 2025çº§åšå£« å¼ ç¿”
- 2025çº§ç¡•å£« ç‹çš“å†¬ï¼Œå¼ è±ª
- 2023çº§æœ¬ç§‘ç”Ÿ ç½—é”¦å½¬

### Graduated
- 2021çº§ç¡•å£« é™ˆç‚³æ˜Šï¼ˆè‹±ä¼Ÿè¾¾ï¼‰
- 2022çº§ç¡•å£« æ¨é¹å®‡ï¼ˆå­—èŠ‚è·³åŠ¨ï¼‰